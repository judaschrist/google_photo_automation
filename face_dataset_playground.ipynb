{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google_photo_api import GooglePhotoHelper\n",
    "import json\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import piexif\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# methods for reading image from google photo API\n",
    "def generate_face_dataset_from_google_album(album_name, size):\n",
    "    '''\n",
    "    return a list of url / name tuple\n",
    "    '''\n",
    "    helper = GooglePhotoHelper()\n",
    "    album_list = helper.find_albums_by_name('Ada')\n",
    "    if len(album_list) != 1:\n",
    "        raise Exception(f'There should be only one album named {album_name}!')\n",
    "    url_list = helper.list_face_download_urls_from_album(album_list[0]['id'], size=size)\n",
    "    return url_list\n",
    "    # data_json_str_list = [json.dumps({\"image_url\": url, \"label\": album_name}) for url in url_list]\n",
    "    # # write json lines to file:\n",
    "    # with open(album_name + '_face_dataset.json', 'w') as f:\n",
    "    #     f.writelines(data_json_str_list)\n",
    "\n",
    "def read_image_info_from_url(url):\n",
    "    r = requests.get(url)\n",
    "    image = Image.open(BytesIO(r.content))\n",
    "    exif_dict = piexif.load(image.info['exif'])\n",
    "    d = r.headers['content-disposition']\n",
    "    fname = re.findall(\"filename=\\\"(.+)\\\"\", d)[0]\n",
    "    return image, fname, exif_dict['Exif'][piexif.ExifIFD.UserComment].decode('utf-8')\n",
    "\n",
    "# read_image_info_from_url('https://lh3.googleusercontent.com/lr/AGiIYOVkJAGcLO64zWnjDlUsmGiCPXis3GPh12ddfPl2xVkoe66w2ZBCRhn1ssWb2lYcAAwg2sQU8IZ6korV0rKYaQGMmV83HR41W2OdIveNXOQXiSLv0-ropDMYRVzcqcWLj-mrbsvh-xmCHU3yrJHyjWeSkRx-WI1oDYv1Urdx2RKBdLq8P6AtfqMl1-pY3rRuh6rSryHCm985IUqzkFEVzNaScgcnhuRUbTssxI1uMmqAFpIdeB_AlhMzNIjjSzsK8nNMTcFbCV1tWWxNmRbBuvPmm89O12mDwX48RrL7TamdqdiscVta7awGPHTA0e6mKj1EFTtcDTDmFTqaz1FczpbrAyYd3fd9bcInsCMFkVaVAVIhRt2xEFmmPS2IqR7JpaRA1AMZLxCJx8Fh8BwO6Gy5XEyrRQ7n1Wlf--_1eZxPJUUUyFjuZsVNV_aN7ALij4EfwxyohxfQLPghTmRVGsdeNW5cpW2zOhiNlW66YObVYs9sttzIbX72iTkJ2khcdey92_f5fJaaDYPxDRL_RRsIRVqZm-Wznt5HvdQFJtGF63GjVcmp7kEfg4kl650golimA5DpytpSNkLQgrxFhkk8SFW5PsuUdfh89hgFy0ETEEe0sxlXm071uL3pUm70hMMuRSGAFZBl8IIy0I_Q-Y7akpZpYfGEt3vw9TSBDpsmHlhZtQLmEEDX1a47aHaZty_BCy8sGWwW6G2s3v00kqhY3VJVYNPETMIztlwWlt8bvLg0MLWLj3V5d_ypBdFDme73kn-q9EtT3JfngVcv8heqVEOOAD4OKF8Iy0j3VlbCspgCXfaNFz8ZPW-Iwb68HfO7DS_awX7FM5R_hB_6DHTzEkH0CvQzxGjv6L0hEDA4t8rLr4WkWnNm5IGkMkU2Xs4_wxgVHN24vjxvpUMKYTBJIbWefcH6muxDT1JuCp6OOIpMAprL527H4Buv2Wgzp4dlDVpba7pFROKGFTfwdYXeF7SOxvZU1KCRplFwDgPuwIDBwMZ09rqHZ-EAnggaU2Qmuu0N7EaQG2pmf9NlGpRBCJjAa4-U__avpagJpHmvbtZ0jJM=d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "# image preprocessing\n",
    "# get the median hight/width ratio of the images\n",
    "def get_median_height_width_ratio(image_paths):\n",
    "    height_width_ratios = []\n",
    "    for image_path in image_paths:\n",
    "        image = Image.open(image_path)\n",
    "        width, height = image.size\n",
    "        height_width_ratios.append(height / width)\n",
    "    return np.median(height_width_ratios)\n",
    "\n",
    "def get_roll_pan_tilt_from_image(file_path):\n",
    "    '''\n",
    "    read roll angle, pan angle, tilt angle from image object\n",
    "    '''\n",
    "    image = Image.open(file_path)\n",
    "    try:\n",
    "        exif_dict = piexif.load(image.info['exif'])\n",
    "        user_comment = exif_dict['Exif'][piexif.ExifIFD.UserComment].decode('utf-8')\n",
    "        face_json = json.loads(user_comment)\n",
    "        return face_json['rollAngle'], face_json['panAngle'], face_json['tiltAngle']\n",
    "    except KeyError:\n",
    "        return None, None, None\n",
    "    \n",
    "\n",
    "def is_file_valid_face_image(file_path):\n",
    "    if file_path.endswith('.jpg') and 'auto_detected_face_image_' in file_path:\n",
    "        image = Image.open(file_path)\n",
    "        width, height = image.size\n",
    "        if abs(height / width - 1.162) > 0.08:\n",
    "            return False\n",
    "        # parse date from the file name\n",
    "        date_string = re.findall(\"auto_detected_face_image_(.+)_\\d+_\", file_path)[0]\n",
    "        # image hight/width ratio should be around 1.162\n",
    "        # print(f\"median height/width ratio: {get_median_height_width_ratio(image_paths)}\")\n",
    "        try:\n",
    "            datetime.strptime(date_string, '%Y:%m:%d')\n",
    "            roll, pan, tilt = get_roll_pan_tilt_from_image(file_path)\n",
    "            if roll is None or pan is None or tilt is None:\n",
    "                return False\n",
    "            return -6 < pan < 6 and -6 < tilt < 6\n",
    "        except ValueError:\n",
    "            return False\n",
    "\n",
    "def get_date_from_image_path(path):\n",
    "    date_string = re.findall(\"auto_detected_face_image_(.+)_\\d+_\", path)[0]\n",
    "    return datetime.strptime(date_string, '%Y:%m:%d')\n",
    "\n",
    "def read_image_data_from_path(path):\n",
    "    '''\n",
    "    Return the image object, the date object parsed from the name, and the user comment in the Exif\n",
    "    '''\n",
    "    image = Image.open(path)\n",
    "    try:\n",
    "        exif_dict = piexif.load(image.info['exif'])\n",
    "        user_comment = exif_dict['Exif'][piexif.ExifIFD.UserComment].decode('utf-8')\n",
    "    except KeyError:\n",
    "        user_comment = '{}'\n",
    "    return image, get_date_from_image_path(path), user_comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total eligible images: 397\n"
     ]
    }
   ],
   "source": [
    "# valid image selection\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "\n",
    "# def show_face_image_grid(dir):\n",
    "dir = '/Users/lingxiao/Documents/ada_faces'\n",
    "# fig = plt.figure(figsize=(columns, rows))\n",
    "# # set the size of the image\n",
    "# fig.set_size_inches(image_w * columns, image_h * rows)\n",
    "# read image paths from directory and open with pillow\n",
    "image_paths = [os.path.join(dir, f) for f in os.listdir(dir) if os.path.isfile(os.path.join(dir, f)) and is_file_valid_face_image(os.path.join(dir, f))]\n",
    "print(f\"total eligible images: {len(image_paths)}\")\n",
    "\n",
    "# print(image_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff in day: 498, diff per image: 4.98\n",
      "sampled images: 99\n"
     ]
    }
   ],
   "source": [
    "import imageio\n",
    "from PIL import ImageDraw, ImageFont\n",
    "from datetime import timedelta\n",
    "import math\n",
    "\n",
    "def uniform_sample_from_image_paths(image_paths, sample_size):\n",
    "    '''\n",
    "    sample images from the image paths with uniform distribution based on dates\n",
    "    '''\n",
    "\n",
    "    sorted_list_dates = sorted(list([get_date_from_image_path(path) for path in image_paths]))\n",
    "    sorted_path = sorted(image_paths, key=lambda path: get_date_from_image_path(path))\n",
    "\n",
    "    diff_in_day = (sorted_list_dates[-1] - sorted_list_dates[0]).days\n",
    "    diff_per_image = diff_in_day / sample_size\n",
    "    print(f\"diff in day: {diff_in_day}, diff per image: {diff_per_image}\")\n",
    "\n",
    "    cur_date = sorted_list_dates[0]\n",
    "    sampled_image_paths = []\n",
    "    image_count = 0\n",
    "    i = 0\n",
    "    while i < len(sorted_list_dates) and cur_date < sorted_list_dates[-1] and image_count < sample_size:\n",
    "        # get the date in the list that is closest to the current date\n",
    "        i = min(range(i, len(sorted_list_dates)), key=lambda i: abs(sorted_list_dates[i] - cur_date))\n",
    "        sampled_image_paths.append(sorted_path[i])\n",
    "        cur_date += timedelta(days=diff_per_image)\n",
    "        image_count += 1\n",
    "        i += 1\n",
    "    return sampled_image_paths\n",
    "\n",
    "def read_landmark_x_y_from_user_comment(user_comment, landmark_type):\n",
    "    face_json = json.loads(user_comment)\n",
    "    landmarks = face_json['landmarks']\n",
    "    boundingpoly_x = face_json['boundingPoly']['vertices'][0].get('x', 0) \n",
    "    boundingpoly_y = face_json['boundingPoly']['vertices'][0].get('y', 0)\n",
    "    for landmark in landmarks:\n",
    "        if landmark['type'] == landmark_type:\n",
    "            return landmark['position']['x']-boundingpoly_x, landmark['position']['y']-boundingpoly_y\n",
    "    return None, None\n",
    "\n",
    "def align_image(image, user_comment, file_path):\n",
    "    left_eye_x, left_eye_y = read_landmark_x_y_from_user_comment(user_comment, 'LEFT_EYE')\n",
    "    right_eye_x, right_eye_y = read_landmark_x_y_from_user_comment(user_comment, 'RIGHT_EYE')\n",
    "    if left_eye_x is None or left_eye_y is None or right_eye_x is None or right_eye_y is None:\n",
    "        return None\n",
    "    # crop the image so the eyes are in the same relative position\n",
    "    eye_distance = ((right_eye_x - left_eye_x)**2 + (right_eye_y - left_eye_y)**2)**0.5\n",
    "    eye_center_x = (right_eye_x + left_eye_x) / 2\n",
    "    eye_center_y = (left_eye_y + right_eye_y) / 2\n",
    "    crop_left = eye_center_x - eye_distance * 1.42\n",
    "    crop_right = eye_center_x + eye_distance * 1.42\n",
    "    image_h = image.size[1]\n",
    "    crop_up = eye_center_y - image_h * 0.45\n",
    "    crop_down = eye_center_y + image_h * 0.48\n",
    "    image = image.crop((crop_left, crop_up, crop_right, crop_down))        \n",
    "    \n",
    "    # rotate the image\n",
    "    angle = math.atan((right_eye_y - left_eye_y) / (right_eye_x - left_eye_x)) * 180 / math.pi\n",
    "    image = image.rotate(angle, expand=False, center=(eye_center_x, eye_center_y))\n",
    "\n",
    "    # resize the image to the same size\n",
    "    width = 300\n",
    "    height = int(width * 1.162)\n",
    "    image = image.resize((width, height))\n",
    "\n",
    "    # add file name as text to the image for debugging purpose\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    comment_json = json.loads(user_comment)\n",
    "    comment_json.pop('landmarks')\n",
    "    comment_json.pop('boundingPoly')\n",
    "    comment_json.pop('fdBoundingPoly')\n",
    "    file_name = os.path.basename(file_path)\n",
    "    position_json_str = file_name + '\\n' + json.dumps(comment_json, indent=4)\n",
    "    font = ImageFont.truetype(\"Apple Symbols.ttf\", 15)\n",
    "    draw.text((0, 0), position_json_str, \n",
    "              fill=(255, 255, 255),\n",
    "              font=font)\n",
    "\n",
    "    return image\n",
    "\n",
    "def generate_gif_from_image_paths(image_paths, gif_path, duration):\n",
    "    images = []\n",
    "    user_comments = []\n",
    "    for path in image_paths:\n",
    "        image, _, user_comment = read_image_data_from_path(path)\n",
    "        images.append(image)\n",
    "        user_comments.append(user_comment)\n",
    "\n",
    "    # align the images based on the position of the eyes\n",
    "    images = [align_image(image, user_comment, path) for image, user_comment, path in zip(images, user_comments, image_paths)]\n",
    "    # remove the images that cannot be aligned\n",
    "    images = [image for image in images if image is not None]\n",
    "    \n",
    "    # return a list of numpy arrays of the image data\n",
    "    images = [np.array(image) for image in images]\n",
    "    imageio.mimsave(gif_path, images, duration=duration)\n",
    "\n",
    "\n",
    "sample_size = 100\n",
    "samepled_image_paths = uniform_sample_from_image_paths(image_paths, sample_size)\n",
    "print(f\"sampled images: {len(samepled_image_paths)}\")\n",
    "generate_gif_from_image_paths(samepled_image_paths, 'test.gif', 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data analysis on image landmarks\n",
    "\n",
    "def show_image_in_grids(columns, rows, image_paths):\n",
    "    image_w = 3\n",
    "    image_h = 3\n",
    "    fig = plt.figure(figsize=(image_w*rows, image_h*columns))\n",
    "    grid = ImageGrid(fig, 111,  # similar to subplot(111)\n",
    "                    nrows_ncols=(rows, columns),  # creates grid of axes\n",
    "                    axes_pad=0.1,  # pad between axes in inch.\n",
    "                    )\n",
    "\n",
    "    # sample images from paths based on grid size\n",
    "    sample_image_paths = np.random.choice(image_paths, size=rows*columns, replace=False)\n",
    "\n",
    "    for i, ax in enumerate(grid):\n",
    "        image, date, user_comment = read_image_data_from_path(sample_image_paths[i])\n",
    "        ax.imshow(image)\n",
    "        # face_json = json.loads(user_comment)\n",
    "        # face_json.pop('boundingPoly')\n",
    "        # face_json.pop('fdBoundingPoly')\n",
    "        # landmarks = face_json.pop('landmarks')\n",
    "        left_eye = read_landmark_x_y_from_user_comment(user_comment, 'LEFT_EYE')\n",
    "        right_eye = read_landmark_x_y_from_user_comment(user_comment, 'RIGHT_EYE')\n",
    "        # anno_string = f\"r: {face_json['rollAngle']}\\np: {face_json['panAngle']}\\nt: {face_json['tiltAngle']}\"\n",
    "        anno_string = json.dumps([left_eye, right_eye], indent=2)\n",
    "        ax.text(10, 200, anno_string, color='black', fontsize=10, bbox = dict(facecolor = 'red', alpha = 0.5))\n",
    "        ax.set_title(str(date)[:10])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff in day: 497, diff per image: 9.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x3/dtn8xt411wj799x57x6_yxmw0000gn/T/ipykernel_6740/1363133632.py:60: DeprecationWarning: LANCZOS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "  return image.resize((width, height), Image.LANCZOS)\n"
     ]
    }
   ],
   "source": [
    "# _, _, user_comment = read_image_data_from_path(image_paths[0])\n",
    "\n",
    "# print(user_comment)\n",
    "\n",
    "# show_image_in_grids(1, 1, image_paths)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1834fb9da18f7e0fbd5919a58aa96b4cbd759847e98e261bab9a965075954d0f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
