{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google_photo_api import GooglePhotoHelper\n",
    "import json\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import piexif\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# methods for reading image from google photo API\n",
    "def generate_face_dataset_from_google_album(album_name, size):\n",
    "    '''\n",
    "    return a list of url / name tuple\n",
    "    '''\n",
    "    helper = GooglePhotoHelper()\n",
    "    album_list = helper.find_albums_by_name('Ada')\n",
    "    if len(album_list) != 1:\n",
    "        raise Exception(f'There should be only one album named {album_name}!')\n",
    "    url_list = helper.list_face_download_urls_from_album(album_list[0]['id'], size=size)\n",
    "    return url_list\n",
    "    # data_json_str_list = [json.dumps({\"image_url\": url, \"label\": album_name}) for url in url_list]\n",
    "    # # write json lines to file:\n",
    "    # with open(album_name + '_face_dataset.json', 'w') as f:\n",
    "    #     f.writelines(data_json_str_list)\n",
    "\n",
    "def read_image_info_from_url(url):\n",
    "    r = requests.get(url)\n",
    "    image = Image.open(BytesIO(r.content))\n",
    "    exif_dict = piexif.load(image.info['exif'])\n",
    "    d = r.headers['content-disposition']\n",
    "    fname = re.findall(\"filename=\\\"(.+)\\\"\", d)[0]\n",
    "    return image, fname, exif_dict['Exif'][piexif.ExifIFD.UserComment].decode('utf-8')\n",
    "\n",
    "# read_image_info_from_url('https://lh3.googleusercontent.com/lr/AGiIYOVkJAGcLO64zWnjDlUsmGiCPXis3GPh12ddfPl2xVkoe66w2ZBCRhn1ssWb2lYcAAwg2sQU8IZ6korV0rKYaQGMmV83HR41W2OdIveNXOQXiSLv0-ropDMYRVzcqcWLj-mrbsvh-xmCHU3yrJHyjWeSkRx-WI1oDYv1Urdx2RKBdLq8P6AtfqMl1-pY3rRuh6rSryHCm985IUqzkFEVzNaScgcnhuRUbTssxI1uMmqAFpIdeB_AlhMzNIjjSzsK8nNMTcFbCV1tWWxNmRbBuvPmm89O12mDwX48RrL7TamdqdiscVta7awGPHTA0e6mKj1EFTtcDTDmFTqaz1FczpbrAyYd3fd9bcInsCMFkVaVAVIhRt2xEFmmPS2IqR7JpaRA1AMZLxCJx8Fh8BwO6Gy5XEyrRQ7n1Wlf--_1eZxPJUUUyFjuZsVNV_aN7ALij4EfwxyohxfQLPghTmRVGsdeNW5cpW2zOhiNlW66YObVYs9sttzIbX72iTkJ2khcdey92_f5fJaaDYPxDRL_RRsIRVqZm-Wznt5HvdQFJtGF63GjVcmp7kEfg4kl650golimA5DpytpSNkLQgrxFhkk8SFW5PsuUdfh89hgFy0ETEEe0sxlXm071uL3pUm70hMMuRSGAFZBl8IIy0I_Q-Y7akpZpYfGEt3vw9TSBDpsmHlhZtQLmEEDX1a47aHaZty_BCy8sGWwW6G2s3v00kqhY3VJVYNPETMIztlwWlt8bvLg0MLWLj3V5d_ypBdFDme73kn-q9EtT3JfngVcv8heqVEOOAD4OKF8Iy0j3VlbCspgCXfaNFz8ZPW-Iwb68HfO7DS_awX7FM5R_hB_6DHTzEkH0CvQzxGjv6L0hEDA4t8rLr4WkWnNm5IGkMkU2Xs4_wxgVHN24vjxvpUMKYTBJIbWefcH6muxDT1JuCp6OOIpMAprL527H4Buv2Wgzp4dlDVpba7pFROKGFTfwdYXeF7SOxvZU1KCRplFwDgPuwIDBwMZ09rqHZ-EAnggaU2Qmuu0N7EaQG2pmf9NlGpRBCJjAa4-U__avpagJpHmvbtZ0jJM=d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "# image preprocessing\n",
    "# get the median hight/width ratio of the images\n",
    "def get_median_height_width_ratio(image_paths):\n",
    "    height_width_ratios = []\n",
    "    for image_path in image_paths:\n",
    "        image = Image.open(image_path)\n",
    "        width, height = image.size\n",
    "        height_width_ratios.append(height / width)\n",
    "    return np.median(height_width_ratios)\n",
    "\n",
    "def get_roll_pan_tilt_from_image(file_path):\n",
    "    '''\n",
    "    read roll angle, pan angle, tilt angle from image object\n",
    "    '''\n",
    "    image = Image.open(file_path)\n",
    "    try:\n",
    "        exif_dict = piexif.load(image.info['exif'])\n",
    "        user_comment = exif_dict['Exif'][piexif.ExifIFD.UserComment].decode('utf-8')\n",
    "        face_json = json.loads(user_comment)\n",
    "        return face_json['rollAngle'], face_json['panAngle'], face_json['tiltAngle']\n",
    "    except KeyError:\n",
    "        return None, None, None\n",
    "    \n",
    "\n",
    "def is_file_valid_face_image(file_path):\n",
    "    if file_path.endswith('.jpg') and 'auto_detected_face_image_' in file_path:\n",
    "        image = Image.open(file_path)\n",
    "        width, height = image.size\n",
    "        if abs(height / width - 1.162) > 0.1:\n",
    "            return False\n",
    "        # parse date from the file name\n",
    "        date_string = re.findall(\"auto_detected_face_image_(.+)_\\d+_\", file_path)[0]\n",
    "        # image hight/width ratio should be around 1.162\n",
    "        # print(f\"median height/width ratio: {get_median_height_width_ratio(image_paths)}\")\n",
    "        try:\n",
    "            datetime.strptime(date_string, '%Y:%m:%d')\n",
    "            roll, pan, tilt = get_roll_pan_tilt_from_image(file_path)\n",
    "            if roll is None or pan is None or tilt is None:\n",
    "                return False\n",
    "            return -10 < roll < 10 and -10 < pan < 10 and -10 < tilt < 10\n",
    "        except ValueError:\n",
    "            return False\n",
    "\n",
    "def get_date_from_image_path(path):\n",
    "    date_string = re.findall(\"auto_detected_face_image_(.+)_\\d+_\", path)[0]\n",
    "    return datetime.strptime(date_string, '%Y:%m:%d')\n",
    "\n",
    "def read_image_data_from_path(path):\n",
    "    '''\n",
    "    Return the image object, the date object parsed from the name, and the user comment in the Exif\n",
    "    '''\n",
    "    image = Image.open(path)\n",
    "    try:\n",
    "        exif_dict = piexif.load(image.info['exif'])\n",
    "        user_comment = exif_dict['Exif'][piexif.ExifIFD.UserComment].decode('utf-8')\n",
    "    except KeyError:\n",
    "        user_comment = '{}'\n",
    "    return image, get_date_from_image_path(path), user_comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total eligible images: 646\n"
     ]
    }
   ],
   "source": [
    "# valid image selection\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "\n",
    "# def show_face_image_grid(dir):\n",
    "dir = '/Users/lingxiao/Documents/ada_faces'\n",
    "# fig = plt.figure(figsize=(columns, rows))\n",
    "# # set the size of the image\n",
    "# fig.set_size_inches(image_w * columns, image_h * rows)\n",
    "# read image paths from directory and open with pillow\n",
    "image_paths = [os.path.join(dir, f) for f in os.listdir(dir) if os.path.isfile(os.path.join(dir, f)) and is_file_valid_face_image(os.path.join(dir, f))]\n",
    "print(f\"total eligible images: {len(image_paths)}\")\n",
    "\n",
    "# print(image_paths)\n",
    "\n",
    "def show_image_in_grids(image_paths):\n",
    "    image_w = 3\n",
    "    image_h = 3\n",
    "    columns = 5\n",
    "    rows = 10\n",
    "    fig = plt.figure(figsize=(image_w*rows, image_h*columns))\n",
    "    grid = ImageGrid(fig, 111,  # similar to subplot(111)\n",
    "                    nrows_ncols=(rows, columns),  # creates grid of axes\n",
    "                    axes_pad=0.1,  # pad between axes in inch.\n",
    "                    )\n",
    "\n",
    "    for i, ax in enumerate(grid):\n",
    "        image, date, user_comment = read_image_data_from_path(image_paths[i])\n",
    "        ax.imshow(image)\n",
    "        face_json = json.loads(user_comment)\n",
    "        face_json.pop('boundingPoly')\n",
    "        face_json.pop('fdBoundingPoly')\n",
    "        face_json.pop('landmarks')\n",
    "        anno_string = f\"r: {face_json['rollAngle']}\\np: {face_json['panAngle']}\\nt: {face_json['tiltAngle']}\"\n",
    "        ax.text(10, 200, anno_string, color='black', fontsize=10, bbox = dict(facecolor = 'red', alpha = 0.5))\n",
    "        ax.set_title(str(date)[:10])\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff in day: 486, diff per image: 4.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x3/dtn8xt411wj799x57x6_yxmw0000gn/T/ipykernel_6740/75110685.py:31: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "  sampled_images = [image.resize((width, height), Image.ANTIALIAS) for image in sampled_images]\n"
     ]
    }
   ],
   "source": [
    "import imageio\n",
    "from PIL import ImageDraw\n",
    "from datetime import timedelta\n",
    "\n",
    "sample_size = 100\n",
    "sorted_list_dates = sorted(list([get_date_from_image_path(path) for path in image_paths]))\n",
    "sorted_path = sorted(image_paths, key=lambda path: get_date_from_image_path(path))\n",
    "\n",
    "diff_in_day = (sorted_list_dates[-1] - sorted_list_dates[0]).days\n",
    "diff_per_image = diff_in_day / sample_size\n",
    "print(f\"diff in day: {diff_in_day}, diff per image: {diff_per_image}\")\n",
    "\n",
    "cur_date = sorted_list_dates[0]\n",
    "sampled_image_paths = []\n",
    "image_count = 0\n",
    "i = 0\n",
    "while i < len(sorted_list_dates) and cur_date < sorted_list_dates[-1] and image_count < sample_size:\n",
    "    # get the date in the list that is closest to the current date\n",
    "    i = min(range(i, len(sorted_list_dates)), key=lambda i: abs(sorted_list_dates[i] - cur_date))\n",
    "    sampled_image_paths.append(sorted_path[i])\n",
    "    cur_date += timedelta(days=diff_per_image)\n",
    "    image_count += 1\n",
    "    i += 1\n",
    "\n",
    "\n",
    "# create a list of imge objects\n",
    "sampled_images = [Image.open(path) for path in sampled_image_paths]\n",
    "# resize the images to 300:(300*1.162)\n",
    "width = 300\n",
    "height = int(width * 1.162)\n",
    "sampled_images = [image.resize((width, height), Image.ANTIALIAS) for image in sampled_images]\n",
    "\n",
    "# add file name as text to the image for debugging purpose\n",
    "for i, image in enumerate(sampled_images):\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    draw.text((0, 0), sampled_image_paths[i].split('/')[-1], fill=(255, 255, 255))\n",
    "\n",
    "# return a list of numpy arrays of the image data\n",
    "sampled_images = [np.array(image) for image in sampled_images]\n",
    "imageio.mimsave('test.gif', sampled_images, duration=0.05)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1834fb9da18f7e0fbd5919a58aa96b4cbd759847e98e261bab9a965075954d0f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
